# JanusVLN è®­ç»ƒæ·±åº¦ä¼˜åŒ–æ–¹æ¡ˆ

## å½“å‰ç“¶é¢ˆåˆ†æ
æ ¹æ®æ‚¨çš„è®­ç»ƒæ—¥å¿—ï¼ˆ77.86s/iterï¼Œ620h/epochï¼‰å’Œæ˜¾å­˜å ç”¨ï¼ˆGPUé—´ä¸å‡è¡¡ï¼Œæœ€é«˜78GBï¼‰ï¼Œä¸»è¦ç“¶é¢ˆï¼š

### 1. è§†è§‰ç¼–ç é‡å¤è®¡ç®—ï¼ˆæœ€å¤§ç“¶é¢ˆï¼‰
**é—®é¢˜**ï¼š`modeling_qwen2_5_vl.py:2096-2103` æ¯ä¸ªè®­ç»ƒæ­¥éƒ½å¯¹ 8 å¼ å†å²å›¾åƒé‡æ–°è·‘ VGGT aggregator
- è™½ç„¶åœ¨ `torch.no_grad()` ä¸‹ï¼Œä½†ä»å ç”¨å¤§é‡ CUDA kernel æ—¶é—´
- 8 å¼ å›¾åƒ Ã— batch_size Ã— gradient_accumulation = 64 æ¬¡è§†è§‰ç¼–ç /step
- VGGT å·²å†»ç»“ï¼ˆ`tune_mm_vision=False`ï¼‰ï¼Œè¾“å‡ºå®Œå…¨å¯ç¼“å­˜

**ç†è®ºåŠ é€Ÿ**ï¼š3-5xï¼ˆè§†è§‰ç¼–ç å æ€»æ—¶é—´ ~60-70%ï¼‰

### 2. ZeRO-3 é€šä¿¡å¼€é”€
**é—®é¢˜**ï¼š`stage3_max_live_parameters=1e9` å¯¼è‡´æ¯æ¬¡ forward éƒ½å¹¿æ’­å¤§é‡å‚æ•°
- å½“å‰é…ç½®ä¸‹ï¼Œ8Ã—H800 æ¯æ­¥é€šä¿¡ ~20GB å‚æ•°
- `overlap_comm=true` æ— æ³•å®Œå…¨éšè—é€šä¿¡å»¶è¿Ÿ

**ç†è®ºåŠ é€Ÿ**ï¼š1.5-2xï¼ˆé™ä½ ZeRO stage æˆ–ä¼˜åŒ–å‚æ•°ï¼‰

### 3. æ˜¾å­˜ä¸å‡è¡¡
**ç°è±¡**ï¼šGPU1 å  78GBï¼ŒGPU2 ä»… 46GB
- å¯èƒ½åŸå› ï¼šåŠ¨æ€ batch padding å¯¼è‡´æŸäº› GPU å¤„ç†æ›´å¤šè§†è§‰ token
- `group_by_modality_length=True` åœ¨å° batch ä¸‹æ•ˆæœæœ‰é™

---

## ä¼˜åŒ–æ–¹æ¡ˆï¼ˆåˆ†ä¼˜å…ˆçº§ï¼‰

### ğŸ”¥ ä¼˜å…ˆçº§ P0ï¼šè§†è§‰ç‰¹å¾ç¼“å­˜ï¼ˆç«‹å³å®æ–½ï¼‰

#### æ–¹æ¡ˆ Aï¼šè®­ç»ƒæ—¶ç¼“å­˜è§†è§‰ç‰¹å¾ï¼ˆæ¨èï¼‰
**æ€è·¯**ï¼šåœ¨æ•°æ®é¢„å¤„ç†é˜¶æ®µç¼“å­˜ VGGT è¾“å‡ºï¼Œè®­ç»ƒæ—¶ç›´æ¥åŠ è½½

**å®æ–½æ­¥éª¤**ï¼š
1. æ–°å¢é¢„å¤„ç†è„šæœ¬ `scripts/precompute_visual_features.py`
2. éå†æ‰€æœ‰è®­ç»ƒæ ·æœ¬ï¼Œä¿å­˜ `{trajectory_id}_{step_idx}.pt`
3. ä¿®æ”¹ `vln_data.py`ï¼Œä¼˜å…ˆåŠ è½½ç¼“å­˜ç‰¹å¾
4. è®­ç»ƒæ—¶è·³è¿‡ VGGT forward

**ä¼˜ç‚¹**ï¼š
- åŠ é€Ÿæœ€æ˜¾è‘—ï¼ˆ3-5xï¼‰
- ä¸æ”¹å˜æ¨¡å‹é€»è¾‘
- å¯å¢é‡é¢„è®¡ç®—

**ç¼ºç‚¹**ï¼š
- éœ€è¦é¢å¤–ç£ç›˜ç©ºé—´ï¼ˆä¼°è®¡ 50-100GBï¼Œå–å†³äºè½¨è¿¹æ•°ï¼‰
- é¦–æ¬¡é¢„è®¡ç®—è€—æ—¶ï¼ˆçº¦ 2-4 å°æ—¶ï¼Œä»…éœ€ä¸€æ¬¡ï¼‰

**å®æ–½éš¾åº¦**ï¼šâ­â­ï¼ˆä¸­ç­‰ï¼‰

---

#### æ–¹æ¡ˆ Bï¼šåœ¨çº¿ç¼“å­˜ï¼ˆæ›´ç®€å•ï¼Œä½†åŠ é€Ÿæœ‰é™ï¼‰
**æ€è·¯**ï¼šåœ¨åŒä¸€ epoch å†…ç¼“å­˜å·²è§è¿‡çš„å›¾åƒç‰¹å¾

**ä¿®æ”¹ä½ç½®**ï¼š`modeling_qwen2_5_vl.py` forward å‡½æ•°

**æ ¸å¿ƒé€»è¾‘**ï¼š
```python
# åœ¨ __init__ ä¸­æ·»åŠ 
self.visual_cache = {}  # key: image_hash, value: features

# åœ¨ forward ä¸­ä¿®æ”¹ï¼ˆ2096 è¡Œé™„è¿‘ï¼‰
for k, frame in enumerate(images_vggt[i]):
    frame_hash = hash(frame.data_ptr())  # æˆ–ç”¨å†…å®¹ hash
    if frame_hash in self.visual_cache:
        features = self.visual_cache[frame_hash]
    else:
        # åŸæœ‰çš„ VGGT ç¼–ç é€»è¾‘
        ...
        self.visual_cache[frame_hash] = features
```

**ä¼˜ç‚¹**ï¼š
- æ”¹åŠ¨æœ€å°ï¼ˆ~10 è¡Œä»£ç ï¼‰
- æ— éœ€é¢å¤–å­˜å‚¨

**ç¼ºç‚¹**ï¼š
- é¦– epoch æ— åŠ é€Ÿ
- å†…å­˜å ç”¨å¢åŠ ï¼ˆ~5-10GBï¼Œå¯è®¾ç½® LRU cacheï¼‰
- Dataloader shuffle ä¼šé™ä½å‘½ä¸­ç‡

**å®æ–½éš¾åº¦**ï¼šâ­ï¼ˆç®€å•ï¼‰

---

### ğŸ”¥ ä¼˜å…ˆçº§ P1ï¼šé™ä½ ZeRO stage

#### æ–¹æ¡ˆ Cï¼šåˆ‡æ¢åˆ° ZeRO-2 + CPU offload
**èƒŒæ™¯**ï¼šæ‚¨å·²æµ‹è¯•è¿‡ ZeRO-2 ä¼š OOMï¼Œä½†å¯é€šè¿‡ä»¥ä¸‹é…ç½®è§£å†³ï¼š

**æ–° ZeRO-2 é…ç½®**ï¼ˆ`scripts/zero2_offload.json`ï¼‰ï¼š
```json
{
  "train_batch_size": "auto",
  "train_micro_batch_size_per_gpu": "auto",
  "gradient_accumulation_steps": "auto",
  "gradient_clipping": "auto",
  "zero_allow_untested_optimizer": true,
  "bf16": {"enabled": "auto"},
  "zero_optimization": {
    "stage": 2,
    "offload_optimizer": {
      "device": "cpu",
      "pin_memory": true
    },
    "offload_param": {
      "device": "cpu",
      "pin_memory": true
    },
    "contiguous_gradients": true,
    "overlap_comm": true,
    "reduce_bucket_size": 5e8,
    "allgather_bucket_size": 5e8
  },
  "activation_checkpointing": {
    "partition_activations": true,
    "cpu_checkpointing": true,
    "contiguous_memory_optimization": true,
    "synchronize_checkpoint_boundary": false
  }
}
```

**å…³é”®æ”¹åŠ¨**ï¼š
- `offload_optimizer` + `offload_param`ï¼šå°†ä¼˜åŒ–å™¨çŠ¶æ€å’Œå‚æ•°å¸è½½åˆ° CPU
- `activation_checkpointing.cpu_checkpointing`ï¼šæ¿€æ´»å€¼ä¹Ÿå¸è½½åˆ° CPU
- `reduce_bucket_size` é™ä½åˆ° 500MBï¼Œå‡å°‘é€šä¿¡å»¶è¿Ÿ

**é¢„æœŸæ•ˆæœ**ï¼š
- æ˜¾å­˜å ç”¨ï¼šé™è‡³ ~40-50GB/GPUï¼ˆå¯æ”¯æŒ batch_size=2ï¼‰
- é€Ÿåº¦ï¼šæ¯” ZeRO-3 å¿« 1.5-2xï¼ˆè™½ç„¶æœ‰ CPU-GPU ä¼ è¾“ï¼Œä½†é€šä¿¡é‡å¤§å¹…å‡å°‘ï¼‰

**å®æ–½æ­¥éª¤**ï¼š
```bash
# ä¿®æ”¹ train_h800.sh
DS_CONFIG="./scripts/zero2_offload.json"

# å¯å°è¯•å¢å¤§ batch size
--per_device_train_batch_size 2 \
--gradient_accumulation_steps 4 \
```

**å®æ–½éš¾åº¦**ï¼šâ­ï¼ˆåªéœ€æ”¹é…ç½®æ–‡ä»¶ï¼‰

---

### ğŸ”¥ ä¼˜å…ˆçº§ P2ï¼šä¼˜åŒ–æ•°æ®åŠ è½½

#### æ–¹æ¡ˆ Dï¼šå‡å°‘å›¾åƒåˆ†è¾¨ç‡ï¼ˆè®­ç»ƒé˜¶æ®µï¼‰
**å½“å‰é…ç½®**ï¼š
```bash
--max_pixels $((576*28*28))  # 451,584 pixels
--video_max_frames 8
```

**å»ºè®®è°ƒæ•´**ï¼ˆè®­ç»ƒé˜¶æ®µï¼‰ï¼š
```bash
--max_pixels $((384*28*28))  # 301,056 pixels (-33%)
--min_pixels $((28*28*28))   # å¢åŠ  min_pixels ä¸‹é™
```

**æ•ˆæœ**ï¼š
- æ˜¾å­˜ï¼šé™ä½ 20-30%
- é€Ÿåº¦ï¼šæå‡ 15-20%ï¼ˆIO + è§†è§‰ç¼–ç ï¼‰
- ç²¾åº¦æŸå¤±ï¼š<1%ï¼ˆVLN ä»»åŠ¡å¯¹è¶…é«˜åˆ†è¾¨ç‡ä¸æ•æ„Ÿï¼‰

**éªŒè¯æ–¹æ³•**ï¼šå…ˆè·‘ 100 steps å¯¹æ¯” lossï¼Œè‹¥å·®å¼‚ <5% å¯é‡‡ç”¨

---

#### æ–¹æ¡ˆ Eï¼šä¼˜åŒ– Dataloader
**å½“å‰ç“¶é¢ˆ**ï¼š`dataloader_num_workers=8` å¯èƒ½ä¸è¶³

**å»ºè®®**ï¼š
```python
# train_h800.sh ä¸­å¢åŠ 
--dataloader_num_workers 16 \      # åŠ å€ï¼ˆå¦‚æœ CPU æ ¸å¿ƒå……è¶³ï¼‰
--dataloader_pin_memory True \     # ç¡®ä¿å¼€å¯
--dataloader_prefetch_factor 4 \   # é¢„å– 4 ä¸ª batch
```

**åŒæ—¶åœ¨ `vln_data.py` ä¸­ä¼˜åŒ–å›¾åƒåŠ è½½**ï¼š
```python
# ä½¿ç”¨ PIL-SIMD æˆ– cv2 æ›¿ä»£ PIL.Imageï¼ˆæé€Ÿ 2-3xï¼‰
import cv2

def load_image_fast(path):
    img = cv2.imread(path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return Image.fromarray(img)
```

---

### ğŸ”¥ ä¼˜å…ˆçº§ P3ï¼šå¤šèŠ‚ç‚¹è®­ç»ƒä¼˜åŒ–

#### æ–¹æ¡ˆ Fï¼šè·¨èŠ‚ç‚¹è®­ç»ƒé…ç½®
**æ‚¨æåˆ°"æƒ³åŠæ³•ä½¿ç”¨æ›´å¤šèŠ‚ç‚¹"**ï¼Œä»¥ä¸‹æ˜¯æœ€ä½³å®è·µï¼š

**1. ä¿®æ”¹ `train_h800.sh` æ”¯æŒå¤šèŠ‚ç‚¹**ï¼š
```bash
# åœ¨è„šæœ¬é¡¶éƒ¨æ·»åŠ 
NNODES=${NNODES:-1}              # èŠ‚ç‚¹æ•°
NODE_RANK=${NODE_RANK:-0}        # å½“å‰èŠ‚ç‚¹ rank
MASTER_ADDR=${MASTER_ADDR:-localhost}

# ä¿®æ”¹ torchrun å‚æ•°
"${LAUNCHER[@]}" \
  --nnodes="${NNODES}" \
  --node_rank="${NODE_RANK}" \
  --nproc_per_node="${NPROC_PER_NODE}" \
  --master_addr="${MASTER_ADDR}" \
  --master_port="${MASTER_PORT}" \
  ...
```

**2. å¯åŠ¨å‘½ä»¤ï¼ˆåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šæ‰§è¡Œï¼‰**ï¼š
```bash
# èŠ‚ç‚¹ 0ï¼ˆä¸»èŠ‚ç‚¹ï¼‰
export MASTER_ADDR=192.168.1.100  # ä¸»èŠ‚ç‚¹ IP
export NODE_RANK=0
export NNODES=2
bash scripts/train_h800.sh

# èŠ‚ç‚¹ 1
export MASTER_ADDR=192.168.1.100
export NODE_RANK=1
export NNODES=2
bash scripts/train_h800.sh
```

**3. ä¼˜åŒ–è·¨èŠ‚ç‚¹é€šä¿¡**ï¼š
```bash
# è®¾ç½® NCCL ç¯å¢ƒå˜é‡ï¼ˆåœ¨ train_h800.sh ä¸­ï¼‰
export NCCL_IB_DISABLE=0           # å¯ç”¨ InfiniBand
export NCCL_IB_HCA=mlx5            # IB è®¾å¤‡ï¼ˆæ ¹æ®ç¡¬ä»¶è°ƒæ•´ï¼‰
export NCCL_SOCKET_IFNAME=eth0     # è‹¥ç”¨ä»¥å¤ªç½‘
export NCCL_NET_GDR_LEVEL=5        # GPU Direct RDMA
```

**é¢„æœŸæ•ˆæœ**ï¼ˆ2 èŠ‚ç‚¹ 16 GPUï¼‰ï¼š
- æœ‰æ•ˆ batch size ç¿»å€ï¼ˆå¯å¢å¤§å­¦ä¹ ç‡ï¼‰
- çº¿æ€§åŠ é€Ÿï¼ˆè‹¥ç½‘ç»œå¸¦å®½è¶³å¤Ÿï¼‰

---

## ç»¼åˆä¼˜åŒ–è·¯çº¿å›¾

### é˜¶æ®µ 1ï¼šå¿«é€Ÿä¼˜åŒ–ï¼ˆ1-2 å¤©ï¼‰
1. âœ… **å®æ–½æ–¹æ¡ˆ B**ï¼ˆåœ¨çº¿ç¼“å­˜ï¼‰ï¼š~2 å°æ—¶æ”¹ä»£ç  + æµ‹è¯•
2. âœ… **å®æ–½æ–¹æ¡ˆ D**ï¼ˆé™åˆ†è¾¨ç‡ï¼‰ï¼šæ”¹é…ç½®ç«‹å³ç”Ÿæ•ˆ
3. âœ… **å®æ–½æ–¹æ¡ˆ E**ï¼ˆä¼˜åŒ– dataloaderï¼‰ï¼š~1 å°æ—¶

**é¢„æœŸåŠ é€Ÿ**ï¼š1.5-2xï¼ˆiter æ—¶é—´é™è‡³ 40-50sï¼‰

---

### é˜¶æ®µ 2ï¼šæ·±åº¦ä¼˜åŒ–ï¼ˆ3-5 å¤©ï¼‰
4. âœ… **å®æ–½æ–¹æ¡ˆ A**ï¼ˆé¢„è®¡ç®—ç¼“å­˜ï¼‰ï¼šéœ€è¦å†™é¢„å¤„ç†è„šæœ¬
5. âœ… **å®æ–½æ–¹æ¡ˆ C**ï¼ˆZeRO-2 + offloadï¼‰ï¼šæµ‹è¯•æ˜¾å­˜å’Œé€Ÿåº¦å¹³è¡¡ç‚¹

**é¢„æœŸåŠ é€Ÿ**ï¼š3-4xï¼ˆiter æ—¶é—´é™è‡³ 20-25sï¼‰

---

### é˜¶æ®µ 3ï¼šè§„æ¨¡åŒ–ï¼ˆæŒ‰éœ€ï¼‰
6. âœ… **å®æ–½æ–¹æ¡ˆ F**ï¼ˆå¤šèŠ‚ç‚¹ï¼‰ï¼šè‹¥å•èŠ‚ç‚¹ä¼˜åŒ–åä»ä¸æ»¡è¶³éœ€æ±‚

**é¢„æœŸåŠ é€Ÿ**ï¼šNxï¼ˆN ä¸ºèŠ‚ç‚¹æ•°ï¼Œéœ€è¦é«˜é€Ÿäº’è”ï¼‰

---

## é™„ï¼šç›‘æ§è„šæœ¬

### 1. å®æ—¶è®­ç»ƒååç›‘æ§
```bash
# ä¿å­˜ä¸º scripts/monitor_training.sh
#!/bin/bash
LOG_FILE="$1"
while true; do
  if [[ -f "$LOG_FILE" ]]; then
    # æå–æœ€è¿‘ 10 è¡Œçš„ it/s
    tail -20 "$LOG_FILE" | grep -oP '\d+\.\d+s/it' | tail -1
  fi
  sleep 10
done
```

### 2. æ˜¾å­˜å‡è¡¡æ£€æŸ¥
```python
# ä¿å­˜ä¸º scripts/check_gpu_balance.py
import subprocess
import time

while True:
    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used', 
                             '--format=csv,noheader,nounits'], 
                            capture_output=True, text=True)
    mems = [int(x) for x in result.stdout.strip().split('\n')]
    print(f"GPU Mem: {mems}, Imbalance: {max(mems)-min(mems)}MB")
    time.sleep(5)
```

---

## ä¼˜å…ˆæ¨èå®æ–½é¡ºåº

åŸºäºæ‚¨çš„çº¦æŸï¼ˆä¸åŠ¨ `max_history_images`ï¼Œå¿«é€Ÿè§æ•ˆï¼‰ï¼š

1. **ç«‹å³åš**ï¼ˆä»Šå¤©ï¼‰ï¼š
   - æ–¹æ¡ˆ Dï¼ˆé™åˆ†è¾¨ç‡ï¼‰
   - æ–¹æ¡ˆ Eï¼ˆdataloader ä¼˜åŒ–ï¼‰
   
2. **æœ¬å‘¨åš**ï¼š
   - æ–¹æ¡ˆ Bï¼ˆåœ¨çº¿ç¼“å­˜ï¼‰
   - æ–¹æ¡ˆ Cï¼ˆæµ‹è¯• ZeRO-2ï¼‰

3. **è¯„ä¼°åå†³å®š**ï¼š
   - æ–¹æ¡ˆ Aï¼ˆé¢„è®¡ç®—ï¼Œæ•ˆæœæœ€å¥½ä½†éœ€è¦æ—¶é—´ï¼‰
   - æ–¹æ¡ˆ Fï¼ˆå¤šèŠ‚ç‚¹ï¼Œéœ€è¦ç¡¬ä»¶æ”¯æŒï¼‰

---

## é¢„æœŸæœ€ç»ˆæ€§èƒ½

å‡è®¾å®æ–½æ–¹æ¡ˆ A + C + D + Eï¼š
- **å•æ­¥æ—¶é—´**ï¼š77.86s â†’ **15-20s**ï¼ˆ4-5x åŠ é€Ÿï¼‰
- **Epoch æ—¶é—´**ï¼š620h â†’ **120-150h**ï¼ˆ~5 å¤©ï¼‰
- **æ˜¾å­˜å ç”¨**ï¼š78GB â†’ **45-55GB**ï¼ˆå¯å°è¯•æ›´å¤§ batchï¼‰
- **ååé‡**ï¼š15 samples/s â†’ **60-80 samples/s**

å¦‚æœå†åŠ å¤šèŠ‚ç‚¹ï¼ˆ2 èŠ‚ç‚¹ 16 GPUï¼‰ï¼š
- **Epoch æ—¶é—´**ï¼š120h â†’ **60-70h**ï¼ˆ~3 å¤©ï¼‰

---

## éœ€è¦æˆ‘å¸®æ‚¨å®æ–½å“ªä¸ªæ–¹æ¡ˆï¼Ÿ

æˆ‘å¯ä»¥ç«‹å³æä¾›ï¼š
1. **æ–¹æ¡ˆ B çš„å®Œæ•´ä»£ç **ï¼ˆåœ¨çº¿ç¼“å­˜ï¼Œæ”¹åŠ¨æœ€å°ï¼‰
2. **æ–¹æ¡ˆ A çš„é¢„è®¡ç®—è„šæœ¬**ï¼ˆç¦»çº¿ç¼“å­˜ï¼Œæ•ˆæœæœ€å¥½ï¼‰
3. **æ–¹æ¡ˆ C çš„ ZeRO-2 é…ç½®**ï¼ˆå·²å†™å¥½ï¼Œè§ä¸Šæ–‡ï¼‰
4. **æ–¹æ¡ˆ E çš„æ•°æ®åŠ è½½ä¼˜åŒ–**ï¼ˆå¿«é€Ÿ IOï¼‰

è¯·å‘Šè¯‰æˆ‘ä¼˜å…ˆå®æ–½å“ªä¸ªï¼Œæˆ‘ä¼šæä¾›å¯ç›´æ¥è¿è¡Œçš„ä»£ç ï¼
