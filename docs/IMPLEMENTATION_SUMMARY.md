# è®­ç»ƒä¼˜åŒ–å®æ–½å®Œæˆæ€»ç»“

## âœ… å·²å®æ–½çš„ä¼˜åŒ–æ–¹æ¡ˆ

### 1. **æ–¹æ¡ˆ Aï¼šVGGT ç‰¹å¾é¢„è®¡ç®—ç¼“å­˜** â­â­â­â­â­
**é¢„æœŸåŠ é€Ÿï¼š3-5x**

#### æ ¸å¿ƒæ–‡ä»¶
- `scripts/precompute_vggt_features.py` - é¢„è®¡ç®—è„šæœ¬
- `src/qwen_vl/data/vln_data.py` - æ”¯æŒç¼“å­˜åŠ è½½
- `src/qwen_vl/model/modeling_qwen2_5_vl.py` - è®­ç»ƒæ—¶ä½¿ç”¨ç¼“å­˜
- `src/qwen_vl/train/argument.py` - æ–°å¢ `--vggt_cache_dir` å‚æ•°

#### å·¥ä½œåŸç†
1. **ç¦»çº¿é¢„è®¡ç®—**ï¼šä¸€æ¬¡æ€§å°†æ‰€æœ‰è®­ç»ƒå›¾åƒé€šè¿‡å†»ç»“çš„ VGGT ç¼–ç å™¨ï¼Œä¿å­˜ç‰¹å¾åˆ°ç£ç›˜
2. **è®­ç»ƒåŠ è½½**ï¼šè®­ç»ƒæ—¶ç›´æ¥åŠ è½½é¢„è®¡ç®—ç‰¹å¾ï¼Œè·³è¿‡ VGGT forwardï¼ˆå  60-70% æ—¶é—´ï¼‰
3. **è‡ªåŠ¨é™çº§**ï¼šè‹¥ç¼“å­˜ç¼ºå¤±ï¼Œè‡ªåŠ¨å›é€€åˆ°å®æ—¶ç¼–ç 

#### ä½¿ç”¨æ–¹æ³•
```bash
# ç¬¬ä¸€æ­¥ï¼šé¢„è®¡ç®—ï¼ˆä¸€æ¬¡æ€§ï¼Œ2-4å°æ—¶ï¼‰
python scripts/precompute_vggt_features.py \
  --model_path /path/to/Qwen2.5-VL \
  --vggt_model_path /path/to/VGGT \
  --data_root /path/to/train_data \
  --cache_dir ./cache/vggt_features \
  --verify

# ç¬¬äºŒæ­¥ï¼šå¯ç”¨ç¼“å­˜è®­ç»ƒ
export VGGT_CACHE_DIR=./cache/vggt_features
bash scripts/train_h800.sh
```

#### éªŒè¯æ–¹å¼
è®­ç»ƒæ—¥å¿—ä¸­åº”å‡ºç°ï¼š
```
[INFO] VGGT feature cache enabled: /path/to/cache
[ACCELERATION] Using cached features for batch X
```

---

### 2. **æ–¹æ¡ˆ Cï¼šZeRO-2 + CPU Offload** â­â­â­â­
**é¢„æœŸåŠ é€Ÿï¼š1.5-2xï¼ˆç›¸æ¯” ZeRO-3ï¼‰**

#### æ ¸å¿ƒæ–‡ä»¶
- `scripts/zero2_offload.json` - ZeRO-2 é…ç½®ï¼ˆå« CPU offloadï¼‰

#### é…ç½®ç‰¹ç‚¹
- `stage: 2` - é™ä½é€šä¿¡å¼€é”€
- `offload_optimizer` + `offload_param` - å°†ä¼˜åŒ–å™¨å’Œå‚æ•°å¸è½½åˆ° CPU
- `reduce_bucket_size: 5e8` - å‡å°é€šä¿¡ bucket

#### ä½¿ç”¨æ–¹æ³•
```bash
# ä¿®æ”¹ train_h800.sh
DS_CONFIG="scripts/zero2_offload.json"

# å¯å°è¯•å¢å¤§ batch size
bash scripts/train_h800.sh
```

#### é¢„æœŸæ•ˆæœ
- æ˜¾å­˜å ç”¨ï¼š78GB â†’ **45-55GB**
- é€Ÿåº¦ï¼šæ¯” ZeRO-3 å¿« **1.5x**
- å¯æ”¯æŒ `per_device_batch_size=2`

---

### 3. **æ–¹æ¡ˆ Eï¼šDataloader ä¼˜åŒ–** â­â­â­
**é¢„æœŸåŠ é€Ÿï¼š1.2-1.5x**

#### ä¿®æ”¹å†…å®¹
```bash
# train_h800.sh ä¸­å·²æ›´æ–°ï¼š
--dataloader_num_workers 16          # 8 â†’ 16ï¼ˆåŠ å€ï¼‰
--dataloader_pin_memory True         # ç¡®ä¿å¼€å¯
--dataloader_prefetch_factor 4       # é¢„å– 4 ä¸ª batch
```

#### æ•ˆæœ
- å‡å°‘ GPU ç­‰å¾… CPU æ•°æ®æ—¶é—´
- IO å¯†é›†å‹ä»»åŠ¡åŠ é€Ÿæ˜æ˜¾

---

### 4. **æ–¹æ¡ˆ Fï¼šå¤šèŠ‚ç‚¹è®­ç»ƒè„šæœ¬** â­â­â­â­
**é¢„æœŸåŠ é€Ÿï¼šNxï¼ˆN = èŠ‚ç‚¹æ•°ï¼‰**

#### æ ¸å¿ƒæ–‡ä»¶
- `scripts/train_2node_h800.sh` - æ”¯æŒå¤šèŠ‚ç‚¹çš„è®­ç»ƒè„šæœ¬

#### ç‰¹æ€§
- è‡ªåŠ¨æ£€æµ‹å•èŠ‚ç‚¹/å¤šèŠ‚ç‚¹æ¨¡å¼
- å†…ç½® NCCL/IB ä¼˜åŒ–é…ç½®
- æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–

#### ä½¿ç”¨æ–¹æ³•ï¼ˆ2 èŠ‚ç‚¹ç¤ºä¾‹ï¼‰
```bash
# èŠ‚ç‚¹ 0ï¼ˆä¸»èŠ‚ç‚¹ï¼‰
export MASTER_ADDR=192.168.1.100
export NODE_RANK=0
export NNODES=2
bash scripts/train_2node_h800.sh

# èŠ‚ç‚¹ 1ï¼ˆå·¥ä½œèŠ‚ç‚¹ï¼‰
export MASTER_ADDR=192.168.1.100
export NODE_RANK=1
export NNODES=2
bash scripts/train_2node_h800.sh
```

#### NCCL é…ç½®
è„šæœ¬è‡ªåŠ¨å¯ç”¨ï¼š
- InfiniBand æ”¯æŒï¼ˆ`NCCL_IB_DISABLE=0`ï¼‰
- GPU Direct RDMAï¼ˆ`NCCL_NET_GDR_LEVEL=5`ï¼‰
- RoCE æ¨¡å¼ï¼ˆ`NCCL_IB_GID_INDEX=3`ï¼‰

---

### 5. **è®­ç»ƒç›‘æ§å·¥å…·** â­â­â­
**å®æ—¶è¿½è¸ªè®­ç»ƒè¿›åº¦å’Œ GPU è´Ÿè½½**

#### æ ¸å¿ƒæ–‡ä»¶
- `scripts/monitor_training.sh` - å®æ—¶ç›‘æ§è„šæœ¬

#### åŠŸèƒ½
- å®æ—¶æ˜¾ç¤º steps/s å’Œ s/it
- æ¯ 10 ç§’æ›´æ–°ä¸€æ¬¡ GPU æ˜¾å­˜å ç”¨
- è‡ªåŠ¨æ£€æµ‹è®­ç»ƒæ—¥å¿—

#### ä½¿ç”¨æ–¹æ³•
```bash
# å¯åŠ¨ç›‘æ§ï¼ˆä¸è®­ç»ƒå¹¶è¡Œï¼‰
bash scripts/monitor_training.sh /path/to/outputs/train_*.log
```

#### ç¤ºä¾‹è¾“å‡º
```
[2026-02-02 17:30:00] Step: 150 | Speed: 18.5s/it | Throughput: 0.54 steps/s
  GPU Mem (MB): 45123 46890 44567 45678 47890 46123 45890 46234
[2026-02-02 17:30:10] Step: 151 | Speed: 18.2s/it | Throughput: 0.55 steps/s
  GPU Mem (MB): 45234 46912 44589 45701 47901 46145 45912 46256
```

---

## ğŸ“Š é¢„æœŸæ€§èƒ½æå‡

åŸºäºä½ çš„ç¡¬ä»¶ï¼ˆ8Ã— H800ï¼‰å’Œå½“å‰æ—¥å¿—ï¼ˆ77.86s/itï¼‰ï¼š

| ä¼˜åŒ–é˜¶æ®µ | å•æ­¥è€—æ—¶ | Epochæ—¶é—´ | æ€»æ—¶é—´(3 epochs) | åŠ é€Ÿæ¯” |
|---------|---------|----------|----------------|-------|
| **åŸå§‹**ï¼ˆæ— ä¼˜åŒ–ï¼‰ | 77.86s | 620h (~26å¤©) | 1860h (~78å¤©) | 1.0x |
| **+ Dataloaderä¼˜åŒ–** | 65s | 520h | 1560h | **1.2x** |
| **+ VGGTç¼“å­˜** | 18s | 144h (~6å¤©) | 432h (~18å¤©) | **4.3x** |
| **+ ZeRO-2** | 12s | 96h (~4å¤©) | 288h (~12å¤©) | **6.5x** |
| **+ åŒèŠ‚ç‚¹ï¼ˆ16 GPUï¼‰** | 6s | 48h (~2å¤©) | 144h (~6å¤©) | **13x** |

---

## ğŸš€ å»ºè®®å®æ–½é¡ºåº

### ç¬¬ä¸€å¤©ï¼ˆä»Šæ™šï¼‰
1. **å¯åŠ¨é¢„è®¡ç®—è„šæœ¬**ï¼ˆæŒ‚ç€è¿‡å¤œï¼Œ~2-4å°æ—¶ï¼‰
```bash
python scripts/precompute_vggt_features.py \
  --model_path /public/home/vlabadmin/.cache/modelscope/hub/models/Qwen/Qwen2.5-VL-7B-Instruct \
  --vggt_model_path /public/home/vlabadmin/.cache/modelscope/hub/models/facebook/VGGT-1B \
  --data_root /public/home/vlabadmin/dataset/VLN/JanusVLN_Trajectory_Data/trajectory_data/R2R-CE-640x480/train \
  --cache_dir /public/home/vlabadmin/dataset/NewJanusVLN/cache/vggt_features \
  --device cuda:0 \
  --verify
```

### ç¬¬äºŒå¤©ï¼ˆæ˜å¤©ï¼‰
2. **å¯ç”¨ç¼“å­˜è®­ç»ƒï¼ŒéªŒè¯åŠ é€Ÿæ•ˆæœ**
```bash
export VGGT_CACHE_DIR=/public/home/vlabadmin/dataset/NewJanusVLN/cache/vggt_features
bash scripts/train_h800.sh

# å¼€å¯ç›‘æ§ï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
bash scripts/monitor_training.sh /public/home/vlabadmin/dataset/NewJanusVLN/outputs/vln_h800_8gpu/train_*.log
```

3. **è§‚å¯Ÿæ—¥å¿—ç¡®è®¤**ï¼š
   - å•æ­¥æ—¶é—´ä» 77s é™åˆ° **~18s**ï¼ˆ4x åŠ é€Ÿï¼‰
   - æ—¥å¿—å‡ºç° `[ACCELERATION] VGGT cache enabled`

### ç¬¬ä¸‰å¤©
4. **æµ‹è¯• ZeRO-2ï¼ˆå¯é€‰ï¼‰**
```bash
# ä¿®æ”¹ train_h800.sh
DS_CONFIG="scripts/zero2_offload.json"

# å¯å°è¯•
# --per_device_train_batch_size 2
# --gradient_accumulation_steps 4
```

### ç”³è¯·åˆ°åŒèŠ‚ç‚¹å
5. **å¤šèŠ‚ç‚¹è®­ç»ƒ**
```bash
# èŠ‚ç‚¹ 0
export MASTER_ADDR=<node0_ip>
export NODE_RANK=0
export NNODES=2
export VGGT_CACHE_DIR=/shared/cache/vggt_features  # ç¡®ä¿å…±äº«å­˜å‚¨
bash scripts/train_2node_h800.sh

# èŠ‚ç‚¹ 1
export MASTER_ADDR=<node0_ip>
export NODE_RANK=1
export NNODES=2
export VGGT_CACHE_DIR=/shared/cache/vggt_features
bash scripts/train_2node_h800.sh
```

---

## ğŸ” éªŒè¯æ¸…å•

### âœ… é¢„è®¡ç®—é˜¶æ®µ
- [ ] è„šæœ¬è¿è¡Œå®Œæˆï¼Œæ— æŠ¥é”™
- [ ] `cache/vggt_features/` ç›®å½•åŒ…å« `.pt` æ–‡ä»¶
- [ ] `manifest.json` æ˜¾ç¤ºæ­£ç¡®çš„å›¾åƒæ•°é‡
- [ ] `--verify` è¾“å‡ºæ˜¾ç¤ºæ‰€æœ‰ç¼“å­˜æœ‰æ•ˆ

### âœ… è®­ç»ƒé˜¶æ®µ
- [ ] è®­ç»ƒæ—¥å¿—å‡ºç° `[ACCELERATION] VGGT cache enabled`
- [ ] å•æ­¥æ—¶é—´ä» 77s é™åˆ° **15-20s**
- [ ] GPU æ˜¾å­˜å ç”¨ç›¸æ¯”ä¹‹å‰é™ä½æˆ–æŒå¹³
- [ ] `nvidia-smi` æ˜¾ç¤ºæ‰€æœ‰ GPU å‡åœ¨ä½¿ç”¨

### âœ… å¤šèŠ‚ç‚¹é˜¶æ®µ
- [ ] ä¸¤ä¸ªèŠ‚ç‚¹çš„æ—¥å¿—éƒ½æ˜¾ç¤º `NCCL Init COMPLETE`
- [ ] ä¸¤èŠ‚ç‚¹çš„ step æ•°åŒæ­¥å¢é•¿
- [ ] å•æ­¥æ—¶é—´è¿›ä¸€æ­¥å‡åŠ

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

- **è¯¦ç»†ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š`docs/TRAINING_OPTIMIZATION.md`
- **ç¼“å­˜ä½¿ç”¨æŒ‡å—**ï¼š`docs/VGGT_CACHE_GUIDE.md`
- **é¢„è®¡ç®—è„šæœ¬**ï¼š`scripts/precompute_vggt_features.py`
- **å•èŠ‚ç‚¹è®­ç»ƒ**ï¼š`scripts/train_h800.sh`
- **åŒèŠ‚ç‚¹è®­ç»ƒ**ï¼š`scripts/train_2node_h800.sh`
- **å®æ—¶ç›‘æ§**ï¼š`scripts/monitor_training.sh`

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### ç¼“å­˜è·¯å¾„å¿…é¡»ä¸€è‡´
```bash
# é¢„è®¡ç®—æ—¶
--cache_dir /path/to/cache

# è®­ç»ƒæ—¶
--vggt_cache_dir /path/to/cache  # å¿…é¡»ç›¸åŒ
```

### å¤šèŠ‚ç‚¹å…±äº«å­˜å‚¨
- `VGGT_CACHE_DIR` å¿…é¡»åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šå¯è®¿é—®ï¼ˆNFS/å…±äº«å­˜å‚¨ï¼‰
- é¢„è®¡ç®—åªéœ€åœ¨ä¸€ä¸ªèŠ‚ç‚¹è¿è¡Œä¸€æ¬¡

### å›¾åƒåˆ†è¾¨ç‡
- **ä¿æŒä¸å˜**ï¼š`--max_pixels $((576*28*28))`ï¼ˆæŒ‰ä½ çš„è¦æ±‚ï¼‰
- é¢„è®¡ç®—æ—¶ä¼šä½¿ç”¨ç›¸åŒçš„åˆ†è¾¨ç‡è®¾ç½®

### ç£ç›˜ç©ºé—´
- é¢„ç•™ **50-100GB** ç”¨äºç¼“å­˜ç‰¹å¾
- å®šæœŸæ¸…ç†æ—§çš„ checkpointï¼ˆ`--save_total_limit 2`ï¼‰

---

## ğŸ¯ é¢„æœŸæœ€ç»ˆæ•ˆæœ

å®æ–½å…¨éƒ¨ä¼˜åŒ–åï¼ˆå•èŠ‚ç‚¹ + ç¼“å­˜ + ZeRO-2ï¼‰ï¼š

- **è®­ç»ƒé€Ÿåº¦**ï¼š77.86s/it â†’ **12-15s/it**ï¼ˆ**~6x åŠ é€Ÿ**ï¼‰
- **Epoch æ—¶é—´**ï¼š620h â†’ **~100h**ï¼ˆ**4-5 å¤©/epoch**ï¼‰
- **æ€»è®­ç»ƒæ—¶é—´ï¼ˆ3 epochsï¼‰**ï¼š1860h â†’ **~300h**ï¼ˆ**12-13 å¤©**ï¼‰

å¦‚æœåŠ ä¸ŠåŒèŠ‚ç‚¹ï¼ˆ16 GPUï¼‰ï¼š

- **Epoch æ—¶é—´**ï¼šâ†’ **~50h**ï¼ˆ**2 å¤©/epoch**ï¼‰
- **æ€»è®­ç»ƒæ—¶é—´ï¼ˆ3 epochsï¼‰**ï¼šâ†’ **~150h**ï¼ˆ**6-7 å¤©**ï¼‰

---

## éœ€è¦å¸®åŠ©ï¼Ÿ

é‡åˆ°é—®é¢˜è¯·æ£€æŸ¥ï¼š
1. æ—¥å¿—æ–‡ä»¶ï¼š`tail -200 /path/to/outputs/train_*.log`
2. GPU çŠ¶æ€ï¼š`nvidia-smi`
3. ç¼“å­˜ç›®å½•ï¼š`ls -lh /path/to/cache/vggt_features/ | head -20`
4. è¿›ç¨‹çŠ¶æ€ï¼š`ps aux | grep train_vln`

---

**æ‰€æœ‰ä»£ç å·²å°±ç»ªï¼Œå¯ä»¥ç«‹å³å¼€å§‹é¢„è®¡ç®—ï¼** ğŸš€
